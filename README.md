# AISD-interviewAssignment
---

## 項目概述

此項目是一個機器學習應用，旨在使用 XGBoost 分類器預測銀行客戶的流失（Exited）情況。項目通過預處理數據、處理類別不平衡、訓練 XGBoost 模型，並在測試數據上應用模型來生成流失預測。

## 安裝指南

在開始之前，您需要安裝 Python 和以下依賴庫：

- pandas
- numpy
- scikit-learn
- xgboost
- matplotlib
- seaborn

您可以使用 pip 安裝這些依賴：

```bash
pip install pandas numpy scikit-learn xgboost matplotlib seaborn
```

## 文件結構

- `train.csv` - 訓練數據集文件，包含客戶信息和他們是否流失的標籤。
- `test.csv` - 測試數據集文件，包含客戶信息，不包含流失標籤。
- `main.py` - 主腳本文件，包含數據預處理、模型訓練和評估等所有步驟。
- `README.md` - 說明文件，提供項目概述、安裝指南和使用方法。

## 使用方法

1. 確保所有數據文件（`train.csv` 和 `test.csv`）位於腳本相同的目錄下。
2. 在命令行中運行以下命令來執行腳本：

```bash
python main.py
```

運行後，腳本將處理數據、訓練模型並對測試數據進行預測，結果將保存在名為 `predictions.csv` 的新文件中。

## 功能描述

- **數據預處理**：包括刪除無關特徵、編碼分類變量、轉換數據類型以及特徵縮放。
- **處理類別不平衡**：使用隨機下採樣技術平衡數據集中的類別，這有助於提高模型對少數類的識別能力，從而提高整體預測精度和模型的實用價值。
- **模型訓練與評估**：使用 XGBoost 進行分類，並提供詳盡的模型評估報告，包括準確率、精確率、召回率和 F1 分數。
- **預測與結果輸出**：對測試數據進行預測，輸出包含預測結果的 CSV 文件。

---

為了在您的 README.md 文件中更全面解釋為什麼選擇使用 XGBoost 作為預測模型，您可以在功能描述部分添加以下段落：

---

# 為什麼選擇 XGBoost

在眾多機器學習算法中，我們選擇 XGBoost（eXtreme Gradient Boosting）作為預測模型的核心，主要基於以下幾個理由：

- **高效性能**：XGBoost 是一種基於樹的學習算法，它利用梯度提升框架，能夠在保證學習精度的同時，提供快速的執行效率。
- **模型穩健性**：XGBoost 內置了多種正則化技術，能有效減少模型過擬合，提高模型的泛化能力，這對於我們數據集中的不平衡類別特別重要。
- **靈活調整能力**：XGBoost 支持用戶對學習目標和評估準則進行自定義，提供了豐富的參數設置來調整模型行為，以適應不同的數據特性和需求。
- **處理缺失值**：XGBoost 可以自動處理數據中的缺失值，這對於實際應用中經常遇到的不完整數據集尤其有用。
- **良好的社區支持**：XGBoost 擁有活躍的開發和用戶社區，提供了大量的教程和實踐指南，這有助於解決實際應用中的問題。

這些特點使得 XGBoost 在金融行業中的客戶流失預測問題上表現出色，能夠更精確地預測哪些客戶可能會流失。通過針對性地調整模型參數，我們能夠達到更高的預測準確率和良好的模型解釋性，從而在項目中實現顯著的業務價值。

---

